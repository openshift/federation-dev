# Application Portability
On occasion it may required to move an application off of a cluster or ensure that no traffic is routed to the cluster. To do this we will modify the deployment values within the deployment overlays that were used when we created the pacman application in the last lab.

Before we begin we will validate that every cluster is running the pacman application.
~~~sh
for cluster in cluster1 cluster2 cluster3;do echo "*** $cluster ***"; oc get deployment --context $cluster -n pacman;done

*** cluster1 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   1/1     0            0           6m21s
*** cluster2 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   1/1     1            1           6m21s
*** cluster3 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   1/1     0            0           6m21s
~~~

We would first like to ensure that cluster1 does not have any replicas running at all. To do this we will modify the file `~/federation-dev/labs/lab-7-assets/overlays/cluster1/pacman-deployment.yaml`.

~~~sh
cd ~/federation-dev/labs/lab-7-assets
sed -i 's/replicas: 1/replicas: 0/g' overlays/cluster1/pacman-deployment.yaml
git commit -am 'Cluster1 replicas scaled to 0'
git push origin master
~~~

We will run the sync command to speed up the process of setting the replicas to 0.
~~~sh
wait-for-argo-app cluster1-pacman
argocd app sync cluster1-pacman
~~~

You can go ahead and play Pacman, you should see that Pacman application requests are load balanced across all two remaining clusters. To get the url for pacman run the following.

~~~sh
oc --context=cluster1 -n haproxy-lb get route haproxy-lb -o jsonpath='{.status.ingress[*].host}'
~~~

We can also remove cluster2 which would only allow cluster3 to run the game.
~~~sh
sed -i 's/replicas: 1/replicas: 0/g' overlays/cluster2/pacman-deployment.yaml
git commit -am 'Cluster2 replicas scaled to 0'
git push origin master
~~~

Again, we will run the sync command to speed up the process of setting the replicas to 0 in cluster2.
~~~sh
wait-for-argo-app cluster2-pacman
argocd app sync cluster2-pacman
~~~

~~~sh
for cluster in cluster1 cluster2 cluster3;do echo "*** $cluster ***"; oc get deployment --context $cluster -n pacman;done

*** cluster1 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   0/0     0            0           7m51s
*** cluster2 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   0/0     0            0           7m32s
*** cluster3 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   1/1     1            1           7m31s
~~~

You can go ahead and play Pacman, you should see that Pacman application is now running on only cluster3. To get the url for pacman run the following.
~~~sh
oc --context=cluster1 -n haproxy-lb get route haproxy-lb -o jsonpath='{.status.ingress[*].host}'
~~~

To populate the application back to all clusters, modify the replica count to be 1 for both cluster1 and cluster2.
~~~sh
sed -i 's/replicas: 0/replicas: 1/g' overlays/cluster1/pacman-deployment.yaml
sed -i 's/replicas: 0/replicas: 1/g' overlays/cluster2/pacman-deployment.yaml
git commit -am 'Scale back cluster1 and cluster2 to 1'
git push origin master
~~~

We will run the sync command which will place pacman pods in all three clusters.

~~~sh
wait-for-argo-app cluster1-pacman
argocd app sync cluster1-pacman
wait-for-argo-app cluster2-pacman
argocd app sync cluster2-pacman
~~~

> NOTE: When running the sync command the resources may already be created because we set `--sync-policy automated` when creating the app in Argo CD.

Verify the deployments have the required replicas again in all three clusters.

~~~sh
for cluster in cluster1 cluster2 cluster3;do echo "*** $cluster ***"; oc get deployment --context $cluster -n pacman;done

*** cluster1 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   1/1     1            1           24s
*** cluster2 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   1/1     1            1           9m24s
*** cluster3 ***
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
pacman   1/1     1            1           25s
~~~

The most important thing to note during the modification of which clusters are running the
*pacman* application is that the scores persist regardless of which cluster the application is running and HAProxy always ensures the application is available.

Next Lab: [Lab 9 - Canary Deployments](./9.md)<br>
Previous Lab: [Lab 7 - Deploying Pacman](./7.md)<br>
[Home](./README.md)
